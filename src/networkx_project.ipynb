{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_citation_graph(dataframe):\n",
    "    graph = nx.DiGraph()  \n",
    "    nodes_list = set()\n",
    "    edges_list = set()\n",
    "    \n",
    "    for paper_id in set(dataframe[\"id\"]):\n",
    "        nodes_list.add(str(paper_id))\n",
    "    \n",
    "    current = 1    \n",
    "    for paper_id in set(dataframe[\"id\"]):\n",
    "        percentage = (current / len(dataframe.axes[0]) * 100)\n",
    "        print(f\"Current percentage: {percentage: .2f}%\", end = \"\\r\")\n",
    "        \n",
    "        current_paper = tuple(dataframe.loc[dataframe[\"id\"] == paper_id].iloc[0])\n",
    "        references = current_paper[7]\n",
    "        for reference_id in references:\n",
    "            if reference_id in nodes_list:\n",
    "                edges_list.add( (str(paper_id), reference_id) )\n",
    "        current += 1\n",
    "    \n",
    "    graph.add_nodes_from(nodes_list)\n",
    "    graph.add_edges_from(edges_list)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def create_weighted_citation_graph(papers, similarities):\n",
    "    graph = nx.DiGraph()  \n",
    "    nodes_list = set()\n",
    "    edges_list = []\n",
    "    \n",
    "    for paper_id in set(papers[\"id\"]):\n",
    "        nodes_list.add(str(paper_id))\n",
    "    \n",
    "    current = 1    \n",
    "    for paper_id in set(papers[\"id\"]):\n",
    "        percentage = (current / len(papers.axes[0]) * 100)\n",
    "        print(f\"Current percentage: {percentage: .2f}%\", end = \"\\r\")\n",
    "        \n",
    "        current_paper = tuple(papers.loc[papers[\"id\"] == paper_id].iloc[0])\n",
    "        references = current_paper[7]\n",
    "        for reference_id in references:\n",
    "            if reference_id in nodes_list:\n",
    "                key = str(paper_id) + \"_\" + reference_id\n",
    "                current_similarity = tuple(similarities.loc[similarities[\"id\"] == key].iloc[0])\n",
    "                edges_list.append( (str(paper_id), reference_id, current_similarity[1]) )\n",
    "        current += 1\n",
    "    \n",
    "    graph.add_nodes_from(nodes_list)\n",
    "    graph.add_weighted_edges_from(edges_list)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current percentage:  100.00%\r"
     ]
    }
   ],
   "source": [
    "paper_dataframe = pd.read_json(\"data/nlp_papers.json\", dtype={'id': str})\n",
    "citation_graph = create_citation_graph(paper_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = nx.pagerank(citation_graph)\n",
    "sorted_scores = sorted(scores.items(), key = lambda x : x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current percentage:  100.00%\r"
     ]
    }
   ],
   "source": [
    "paper_dataframe = pd.read_json(\"data/nlp_papers.json\", dtype={'id': str})\n",
    "similarity_dataframe = pd.read_json(\"data/similarities.json\", dtype={'id': str})\n",
    "weighted_citation_graph = create_weighted_citation_graph(paper_dataframe, similarity_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_scores = nx.pagerank(weighted_citation_graph)\n",
    "weighted_sorted_scores = sorted(weighted_scores.items(), key = lambda x : x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_stats(graph, scores, weighted):\n",
    "    dataframe_dict = {\"paper_id\": [], \"total_citations\": [], \"graph_citations\": [], \"pagerank\": []}\n",
    "\n",
    "    for item in scores:\n",
    "        input_links = graph.in_edges(item[0])\n",
    "        \n",
    "        dataframe_dict[\"paper_id\"].append(item[0])\n",
    "        dataframe_dict[\"total_citations\"].append(0)\n",
    "        dataframe_dict[\"graph_citations\"].append(len(input_links))\n",
    "        dataframe_dict[\"pagerank\"].append(item[1])\n",
    "\n",
    "    df = pd.DataFrame(dataframe_dict)\n",
    "    if weighted:\n",
    "        df.to_csv(\"data/weighted_stats.csv\")\n",
    "    else: df.to_csv(\"data/regular_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nodes_stats(citation_graph, sorted_scores, False)\n",
    "get_nodes_stats(weighted_citation_graph, weighted_sorted_scores, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraph(graph, start_node):\n",
    "    sub = nx.DiGraph()\n",
    "    nodes_list = set()\n",
    "    edges_list = []\n",
    "    \n",
    "    ancestors = nx.ancestors(graph, start_node)\n",
    "    for item in ancestors: nodes_list.add(item)\n",
    "    \n",
    "    edges_list += graph.in_edges(start_node, data = True)\n",
    "    \n",
    "    for node in nodes_list:\n",
    "        edges_list += graph.in_edges(node, data = True)\n",
    "        \n",
    "    sub.add_nodes_from(nodes_list)\n",
    "    sub.add_edges_from(edges_list)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('85173568550', '85173572846', {})\n",
      "('85173568550', '85173566625', {})\n",
      "('85173568550', '85173556632', {})\n",
      "('85173572600', '85173572846', {})\n",
      "('85173563565', '85173572846', {})\n",
      "('85173557933', '85173572846', {})\n",
      "('85175331754', '85173559430', {})\n",
      "('85175346912', '85173559430', {})\n",
      "('85173571982', '85173572846', {})\n",
      "('85173558408', '85173572846', {})\n",
      "('85173563813', '85173572846', {})\n",
      "('85173559671', '85173572846', {})\n",
      "('85177180081', '85173572846', {})\n",
      "('85177180081', '85173566625', {})\n",
      "('85173557366', '85173572846', {})\n",
      "('85173563873', '85173572846', {})\n",
      "('85173563873', '85173568550', {})\n",
      "('85173563873', '85173572600', {})\n",
      "('85175300943', '85173559430', {})\n",
      "('85173561082', '85173572846', {})\n",
      "('85173572746', '85173572846', {})\n",
      "('85173557488', '85173572846', {})\n",
      "('85173572983', '85173572846', {})\n",
      "('85173572983', '85173556632', {})\n",
      "('85173566625', '85173572846', {})\n",
      "('85173566625', '85173568550', {})\n",
      "('85173563969', '85173572846', {})\n",
      "('85173556632', '85173572846', {})\n",
      "('85173556632', '85173559430', {})\n",
      "('85173559430', '85173556632', {})\n",
      "('85173556030', '85173572846', {})\n",
      "('85173572086', '85173572846', {})\n",
      "('85173557600', '85173572846', {})\n",
      "('85173566574', '85173572846', {})\n",
      "('85173566574', '85173556632', {})\n",
      "('85173566574', '85173559430', {})\n",
      "('85173560677', '85173572846', {})\n",
      "('85173572846', '85173566625', {})\n",
      "('85173572846', '85173560677', {})\n"
     ]
    }
   ],
   "source": [
    "sub = create_subgraph(citation_graph, \"85173572846\")\n",
    "for edge in sub.edges(data = True):\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors_name(input_list):\n",
    "    dataframe = pd.read_json(\"data/nlp_authors.json\")\n",
    "    authors = []\n",
    "    \n",
    "    for item in input_list:\n",
    "        row = tuple(dataframe.loc[:, int(item)])\n",
    "        authors.append(row[0] + \" \" + row[1])\n",
    "        \n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_colors(graph):\n",
    "    pagerank_subgraph_scores = []\n",
    "    color_gradients = []\n",
    "    \n",
    "    for node in graph.nodes:\n",
    "        for couple in sorted_scores:\n",
    "            if couple[0] == node: pagerank_subgraph_scores.append(couple)\n",
    "            \n",
    "    pagerank_subgraph_scores.sort(key = lambda x : x[1], reverse = True)\n",
    "\n",
    "    \n",
    "    scores_set = set([x[1] for x in pagerank_subgraph_scores])\n",
    "    max_score = max(scores_set)\n",
    "    min_score = min(scores_set)\n",
    "    \n",
    "    steps = len(scores_set) - 1\n",
    "    count = 1\n",
    "    r_step = (124 - 69) / steps\n",
    "    g_step = (223 - 145) / steps\n",
    "    b_step = (218 - 80) / steps \n",
    "    \n",
    "    for item in pagerank_subgraph_scores:\n",
    "        if item[1] == max_score: color_gradients.append( (item[0], item[1], (124, 223, 80)) )\n",
    "        elif item[1] == min_score: color_gradients.append( (item[0], item[1], (69, 145, 218)) )\n",
    "        else:\n",
    "            color_gradients.append( (item[0], item[1], (round(124 - r_step*count, 0), \n",
    "                                                        round(223 - g_step*count, 0), \n",
    "                                                        round(80 + b_step*count, 0))\n",
    "                                    ) \n",
    "                                   )\n",
    "            count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pagerank-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
